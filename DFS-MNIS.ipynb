{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn.cross_validation as CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation(vector, weights, bias):\n",
    "    return tf.matmul(vector, weights) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchGenerator():\n",
    "    def __init__(self, X, y, batch_size):\n",
    "        self.X = X\n",
    "        self.Y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.n_batch = (len(X) // batch_size)\n",
    "        self.index = 0\n",
    "\n",
    "    def get_batch(self):\n",
    "        batch_range = range(self.index, (self.index+1)*self.batch_size)\n",
    "        if self.index == self.n_batch:\n",
    "            batch_range = range(self.index, len(self.X))\n",
    "        self.index += 1\n",
    "\n",
    "        return self.X[batch_range], self.Y[batch_range]\n",
    "\n",
    "    def resetIndex(self):\n",
    "        self.index = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN layers\n",
    "As far this is ad-hoc solution for test task layer composing fuctions includes code for regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class One2OneLayer(object):\n",
    "    def __init__(self, input_layer, weight_init=None):\n",
    "        input_size = input_layer.get_shape()[1].value\n",
    "\n",
    "        o2o_weights = tf.Variable(tf.random_normal([input_size]))\n",
    "        o2o_output = input_layer * o2o_weights\n",
    "\n",
    "        self.output = o2o_output\n",
    "        self.input = input_layer\n",
    "        self.output = o2o_output\n",
    "        self.weights = o2o_weights\n",
    "    \n",
    "class DenseLayer():\n",
    "    def __init__(self, input_layer, layer_size, activation):\n",
    "        input_size = input_layer.get_shape()[1].value\n",
    "        \n",
    "        weights = tf.Variable(tf.random_normal([input_size, layer_size]))\n",
    "        bias = tf.Variable(tf.random_normal([layer_size]))\n",
    "\n",
    "        z = linear_activation(input_layer, weights, bias)\n",
    "        output = activation(z)\n",
    "        \n",
    "        self.input = input_layer\n",
    "        self.bias = bias\n",
    "        self.output = output\n",
    "        self.weights = weights\n",
    "        \n",
    "class SoftmaxLayer():\n",
    "    \"\"\"\n",
    "        This class describes the outpu layer of NN\n",
    "        with softmax loss function\n",
    "    \"\"\"\n",
    "    def __init__(self, input_layer, layer_size, y):\n",
    "        input_size = input_layer.get_shape()[1].value\n",
    "\n",
    "        weights = tf.Variable(tf.random_normal([input_size, layer_size]))\n",
    "        bias = tf.Variable(tf.random_normal([layer_size]))\n",
    "\n",
    "        z = linear_activation(input_layer, weights, bias)\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=z))\n",
    "\n",
    "        # Evaluate model\n",
    "        correct_predictions = tf.equal(tf.argmax(z, 1), tf.argmax(y, 1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n",
    "        \n",
    "        self.input = input_layer\n",
    "        self.bias = bias\n",
    "        self.output = z\n",
    "        self.weights = weights\n",
    "        \n",
    "        self.cost = cost\n",
    "        self.y = y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepFeatureSelectionNN():\n",
    "    def __init__(self, X, Y, layers_dimentions=100, n_layers=5, activation=tf.nn.sigmoid,\n",
    "                 lambda1=0.001, lambda2=1.0, alpha1=0.001, alpha2=0.0):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "    \n",
    "        #Calculate shapes\n",
    "        n_sample, n_feat = X.shape\n",
    "        n_classes =  Y.shape[1] # len(np.unique(y))\n",
    "    \n",
    "        #Init input layers\n",
    "        self.input_X = tf.placeholder(\"float32\", shape=(None, n_feat), name=\"input_X\")\n",
    "        self.input_y = tf.placeholder(\"float32\", shape=(None, n_classes), name=\"input_Y\")\n",
    "        \n",
    "        #Add one2one, dense and softmax layers\n",
    "        self.hidden_layers = []\n",
    "        self.hidden_layers.append(One2OneLayer(self.input_X))\n",
    "        \n",
    "        dims = []\n",
    "        if type(layers_dimentions) != list:\n",
    "            dims = [layers_dimentions for k in range(n_layers)]\n",
    "        else:\n",
    "            dims = layers_dimentions\n",
    "        \n",
    "        for layer_size in dims:\n",
    "            input_hidden = self.hidden_layers[-1].output if self.hidden_layers else self.input_X\n",
    "            self.hidden_layers.append(DenseLayer(input_hidden, layer_size, activation=activation))\n",
    "            \n",
    "        self.output_layer = SoftmaxLayer(self.hidden_layers[-1].output, n_classes, self.input_y)\n",
    "        self.hidden_layers.append(self.output_layer)\n",
    "        \n",
    "        #Collect weights from layers\n",
    "        w = self.hidden_layers[0].weights\n",
    "        sqr_frob_norm = [tf.norm(l.weights, 'euclidean') ** 2 for l in self.hidden_layers[1:]]\n",
    "        l1_norm = [tf.norm(l.weights, 1) for l in self.hidden_layers[1:]]\n",
    "        \n",
    "        #Precalculate regularization terms\n",
    "        regularization1 = lambda1*((1.0-lambda2) * 0.5 * tf.norm(w) ** 2 + lambda2 * tf.norm(w, 1))\n",
    "        regularization2 = alpha1*((1.0-alpha2) * 0.5 * tf.add_n(sqr_frob_norm) +  lambda1 * tf.add_n(l1_norm))\n",
    "        \n",
    "        #Calculate cost function\n",
    "        self.cost = self.output_layer.cost + regularization1 + regularization2\n",
    "        \n",
    "    def train(self,lerning_rate=0.01, epochs=1000, batch_size=100, \n",
    "              verbose=True, print_step=100, random_state=441):\n",
    "        X_train, X_test, Y_train, Y_test = CV.train_test_split(self.X, \n",
    "                                                               self.Y, \n",
    "                                                               random_state=random_state)\n",
    "        \n",
    "        GDoptimizer = tf.train.AdamOptimizer(lerning_rate)\\\n",
    "                              .minimize(self.cost)\n",
    "        \n",
    "        self.accuracy = self.output_layer.accuracy\n",
    "        #self.y = self.softmax_layer.y\n",
    "        \n",
    "        s = tf.Session()\n",
    "        self.s = s\n",
    "        s.run(tf.global_variables_initializer())\n",
    "        \n",
    "        #batch_generator = BatchGenerator(X_train, Y_train, batch_size)\n",
    "        #n_batch = batch_generator.n_batch\n",
    "        \n",
    "        self.losses, self.train_accs, self.test_accs = [], [], []\n",
    "        \n",
    "        for i in range(epochs):\n",
    "            #batch_generator.resetIndex()\n",
    "            #for j in range(n_batch + 1):\n",
    "                #x_batch, y_batch = batch_generator.get_batch()\n",
    "                \n",
    "            idx = np.random.randint(X_train.shape[0], size=batch_size)\n",
    "            x_batch, y_batch = X_train[idx,:], Y_train[idx,:]\n",
    "                \n",
    "            s.run(GDoptimizer, feed_dict={self.input_X : x_batch, self.input_y: y_batch})\n",
    "\n",
    "            self.train_accs.append(s.run(self.output_layer.accuracy,\n",
    "                                         feed_dict={self.input_X: X_train, self.input_y: Y_train}))\n",
    "            self.test_accs.append(s.run(self.output_layer.accuracy,\n",
    "                                           feed_dict={self.input_X: X_test, self.input_y: Y_test}))\n",
    "            self.losses.append(s.run(self.cost,\n",
    "                                        feed_dict={self.input_X: x_batch, self.input_y: y_batch}))\n",
    "\n",
    "            if verbose and i % print_step == 0:\n",
    "                print('epoch {}: loss = {}'.format(i, self.losses[-1]))\n",
    "                print(\"Train accuracy:\", self.train_accs[-1])\n",
    "                print(\"Test accuracy:\", self.test_accs[-1])\n",
    "\n",
    "                print(\"train auc:\", roc_auc_score(Y_train, s.run(self.output_layer.output, \n",
    "                                                                 {self.input_X: X_train})))\n",
    "                print(\"test auc:\", roc_auc_score(Y_test, s.run(self.output_layer.output, \n",
    "                                                               {self.input_X: X_test})))\n",
    "        \n",
    "        self.selected_ws = s.run(self.hidden_layers[0].weights)\n",
    "        if verbose:\n",
    "            print(\"Final train accuracy:\", self.train_accs[-1])\n",
    "            print(\"Final test accuracy:\", self.test_accs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28) (50000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8cb528f198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from preprocessed_mnist import load_dataset\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_dataset()\n",
    "print(X_train.shape, y_train.shape)\n",
    "%matplotlib inline\n",
    "plt.imshow(X_train[0], cmap=\"Greys\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 784), (10000, 784), (10000, 784))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "Y = np.hstack([y_train, y_val, y_test])\n",
    "Y.shape\n",
    "Y_encoded = enc.fit_transform(np.asmatrix(Y).T).todense()\n",
    "y_train_coded, y_val_coded, y_test_coded = Y_encoded[:50000,:], Y_encoded[50000:60000,:], Y_encoded[60000:,:]\n",
    "y_train_coded.shape, y_val_coded.shape, y_test_coded.shape\n",
    "X_train_f = X_train.reshape([X_train.shape[0], 28*28])\n",
    "X_val_f = X_val.reshape([X_val.shape[0], 28*28])\n",
    "X_test_f = X_test.reshape([X_test.shape[0], 28*28])\n",
    "X_train_f.shape, X_val_f.shape, X_test_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = np.vstack([X_train_f, X_val_f, X_test_f])\n",
    "Y_ = Y_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: loss = 4901.7109375\n",
      "Train accuracy: 0.08135238\n",
      "Test accuracy: 0.07971428\n",
      "train auc: 0.5175752470012721\n",
      "test auc: 0.5164191747965445\n",
      "epoch 100: loss = 604.2279052734375\n",
      "Train accuracy: 0.82321906\n",
      "Test accuracy: 0.818\n",
      "train auc: 0.9474735918000323\n",
      "test auc: 0.9477616152277186\n",
      "epoch 200: loss = 511.8580322265625\n",
      "Train accuracy: 0.8653143\n",
      "Test accuracy: 0.8602286\n",
      "train auc: 0.9592844929430931\n",
      "test auc: 0.9587511485840639\n",
      "epoch 300: loss = 529.4495849609375\n",
      "Train accuracy: 0.89657146\n",
      "Test accuracy: 0.8862857\n",
      "train auc: 0.9659371681866104\n",
      "test auc: 0.9643075289575409\n",
      "epoch 400: loss = 449.665771484375\n",
      "Train accuracy: 0.9081143\n",
      "Test accuracy: 0.8967429\n",
      "train auc: 0.9705304591576225\n",
      "test auc: 0.9685528394355842\n",
      "epoch 500: loss = 407.5274353027344\n",
      "Train accuracy: 0.91958094\n",
      "Test accuracy: 0.9048\n",
      "train auc: 0.9736629951319132\n",
      "test auc: 0.971128708032218\n",
      "epoch 600: loss = 401.86773681640625\n",
      "Train accuracy: 0.9283619\n",
      "Test accuracy: 0.9110857\n",
      "train auc: 0.9752064576528982\n",
      "test auc: 0.9727531478265863\n",
      "epoch 700: loss = 394.0461730957031\n",
      "Train accuracy: 0.934019\n",
      "Test accuracy: 0.9193714\n",
      "train auc: 0.9762846572292874\n",
      "test auc: 0.9734861351761197\n",
      "epoch 800: loss = 402.6553649902344\n",
      "Train accuracy: 0.93902856\n",
      "Test accuracy: 0.92074287\n",
      "train auc: 0.9781258496100425\n",
      "test auc: 0.9751730557558268\n",
      "epoch 900: loss = 422.958740234375\n",
      "Train accuracy: 0.9441905\n",
      "Test accuracy: 0.9242857\n",
      "train auc: 0.9795909433832634\n",
      "test auc: 0.9765599002554997\n",
      "epoch 1000: loss = 358.00341796875\n",
      "Train accuracy: 0.9442667\n",
      "Test accuracy: 0.92457145\n",
      "train auc: 0.980129252854009\n",
      "test auc: 0.9767674141665061\n",
      "epoch 1100: loss = 353.46966552734375\n",
      "Train accuracy: 0.9496762\n",
      "Test accuracy: 0.92714286\n",
      "train auc: 0.9817142807766697\n",
      "test auc: 0.9782184726203443\n",
      "epoch 1200: loss = 360.157470703125\n",
      "Train accuracy: 0.9525333\n",
      "Test accuracy: 0.92994285\n",
      "train auc: 0.9821958168946999\n",
      "test auc: 0.9786368795196111\n",
      "epoch 1300: loss = 349.78875732421875\n",
      "Train accuracy: 0.9594667\n",
      "Test accuracy: 0.93754286\n",
      "train auc: 0.9826958163278572\n",
      "test auc: 0.9791614557094748\n",
      "epoch 1400: loss = 335.40899658203125\n",
      "Train accuracy: 0.95455235\n",
      "Test accuracy: 0.9323429\n",
      "train auc: 0.9837524847212441\n",
      "test auc: 0.9802117794382506\n",
      "epoch 1500: loss = 332.6932678222656\n",
      "Train accuracy: 0.9588571\n",
      "Test accuracy: 0.9350857\n",
      "train auc: 0.9839593342976087\n",
      "test auc: 0.979977041709159\n",
      "epoch 1600: loss = 331.9347229003906\n",
      "Train accuracy: 0.96190476\n",
      "Test accuracy: 0.9374286\n",
      "train auc: 0.9841225904123133\n",
      "test auc: 0.9802485426423834\n",
      "epoch 1700: loss = 335.88824462890625\n",
      "Train accuracy: 0.9654857\n",
      "Test accuracy: 0.9410286\n",
      "train auc: 0.9844139680553026\n",
      "test auc: 0.9807417012412746\n",
      "epoch 1800: loss = 321.0630187988281\n",
      "Train accuracy: 0.9703619\n",
      "Test accuracy: 0.9454857\n",
      "train auc: 0.9851522102944333\n",
      "test auc: 0.9814106690215103\n",
      "epoch 1900: loss = 306.82989501953125\n",
      "Train accuracy: 0.96870476\n",
      "Test accuracy: 0.94542855\n",
      "train auc: 0.986298185219626\n",
      "test auc: 0.982734680509463\n",
      "Final train accuracy: 0.97148573\n",
      "Final test accuracy: 0.9429714\n",
      "CPU times: user 4h 20min 58s, sys: 32min 30s, total: 4h 53min 28s\n",
      "Wall time: 1h 3min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nn = DeepFeatureSelectionNN(X_, Y_, layers_dimentions = [784, 392], activation=tf.nn.relu)\n",
    "nn.train(0.002, 2000, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8c8026a4a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ww = nn.selected_ws.reshape((28,28))\n",
    "\n",
    "plt.title(\"Pixel position importainse in MNIST task\")\n",
    "plt.imshow(ww, cmap=\"Greys\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
